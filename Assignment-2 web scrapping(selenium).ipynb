{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPPING SELENIUM ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\" https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "##To get the web in chrome driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate designations search bar by X path function\n",
    "designation_tags=driver.find_element_by_xpath('//input[@id=\"qsb-keyword-sugg\"]')\n",
    "designation_tags\n",
    "location_tags=driver.find_element_by_xpath('//input[@name=\"location\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To write the designation and location in search bar\n",
    "designation_tags.send_keys(\"Data Analyst\")\n",
    "location_tags.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To click the search buttom\n",
    "button_tags=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "button_tags.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fetch the company name \n",
    "company_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_name=[]\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fetch the job title details:\n",
    "job_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_title=[]\n",
    "for i in job_tags:\n",
    "    job_title.append(i.text)\n",
    "#job_title.insert(0,\"nan\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to fetch the location details:\n",
    "location_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "location=[]\n",
    "for i in location_tags:\n",
    "    location.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to fetch the exp details\n",
    "exp_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "exp=[]\n",
    "for i in exp_tags:\n",
    "    exp.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details={\"job title\":job_title,\n",
    "             \"job Location\":location,\n",
    "             \"company Name\":company_name,\n",
    "             \"Experiance Required\":exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job title</th>\n",
       "      <th>job Location</th>\n",
       "      <th>company Name</th>\n",
       "      <th>Experiance Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immediate job openings For Partner Consultant ...</td>\n",
       "      <td>Bangalore/Bengaluru(Marathahalli)</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Associate - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ Banking Group</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst (Data Stewards)//Immediate Joiner...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Verizon Data Services India Pvt.Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(2nd Phase JP Nagar)</td>\n",
       "      <td>Liventus, Inc.</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst, Component Engineering</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst-Immediate Joiners</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Brillio</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job title  \\\n",
       "0  Immediate job openings For Partner Consultant ...   \n",
       "1                    Senior Associate - Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                                Senior Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5  Data Analyst (Data Stewards)//Immediate Joiner...   \n",
       "6                                Senior Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8                Data Analyst, Component Engineering   \n",
       "9                     Data Analyst-Immediate Joiners   \n",
       "\n",
       "                              job Location  \\\n",
       "0        Bangalore/Bengaluru(Marathahalli)   \n",
       "1                      Bangalore/Bengaluru   \n",
       "2                      Bangalore/Bengaluru   \n",
       "3                      Bangalore/Bengaluru   \n",
       "4                      Bangalore/Bengaluru   \n",
       "5                      Bangalore/Bengaluru   \n",
       "6                      Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru(2nd Phase JP Nagar)   \n",
       "8                      Bangalore/Bengaluru   \n",
       "9                      Bangalore/Bengaluru   \n",
       "\n",
       "                          company Name Experiance Required  \n",
       "0               RANDSTAD INDIA PVT LTD             1-5 Yrs  \n",
       "1                      Publicis Groupe             1-3 Yrs  \n",
       "2                    Applied Materials            7-10 Yrs  \n",
       "3    Flipkart Internet Private Limited             2-5 Yrs  \n",
       "4                    ANZ Banking Group             3-8 Yrs  \n",
       "5                   Tech Mahindra Ltd.            5-10 Yrs  \n",
       "6  Verizon Data Services India Pvt.Ltd             3-6 Yrs  \n",
       "7                       Liventus, Inc.             5-8 Yrs  \n",
       "8                  Rockwell Automation             2-3 Yrs  \n",
       "9                              Brillio             4-6 Yrs  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_result=pd.DataFrame(job_details)\n",
    "job_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Job description\\nBrief about the Role\\nThe Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>Job description\\nRole: Data Scientist\\n\\nRoles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pluto7</td>\n",
       "      <td>Job description\\nResponsibilities:\\nBuild and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Vadodara</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Job description\\nABOUT THIS JOB\\nNielsenIQ Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior/Staff Data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>Job description\\nAbout You\\nYou are a highly m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description\\nJob Responsibilities\\nUse pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IDM - Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description\\nYour responsibilities\\nEnsure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior/Lead Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>AUREUSTECH SYSTEMS PRIVATE LIMITED</td>\n",
       "      <td>Job description\\nResponsibilities\\nIdentify va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pluto7</td>\n",
       "      <td>Job description\\nResponsibilities:\\nBuild NLP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Job description\\nBrief about the Role\\nThe Pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job Title  \\\n",
       "0        Senior Data Scientist   \n",
       "1               Data Scientist   \n",
       "2        Senior Data Scientist   \n",
       "3        Senior Data Scientist   \n",
       "4  Senior/Staff Data scientist   \n",
       "5      Senior Data Scientist I   \n",
       "6    IDM - Lead Data Scientist   \n",
       "7   Senior/Lead Data Scientist   \n",
       "8               Data Scientist   \n",
       "9     Principal Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hyderabad/Secunderabad, Bangalore/Bengaluru, Pune   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3             Chennai, Bangalore/Bengaluru, Vadodara   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                         Company Name  \\\n",
       "0                       24/7 Customer   \n",
       "1                       Wipro Limited   \n",
       "2                              Pluto7   \n",
       "3                             Nielsen   \n",
       "4                              Vmware   \n",
       "5               Philips India Limited   \n",
       "6               Philips India Limited   \n",
       "7  AUREUSTECH SYSTEMS PRIVATE LIMITED   \n",
       "8                              Pluto7   \n",
       "9                       24/7 Customer   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job description\\nBrief about the Role\\nThe Pla...  \n",
       "1  Job description\\nRole: Data Scientist\\n\\nRoles...  \n",
       "2  Job description\\nResponsibilities:\\nBuild and ...  \n",
       "3  Job description\\nABOUT THIS JOB\\nNielsenIQ Adv...  \n",
       "4  Job description\\nAbout You\\nYou are a highly m...  \n",
       "5  Job description\\nJob Responsibilities\\nUse pre...  \n",
       "6  Job description\\nYour responsibilities\\nEnsure...  \n",
       "7  Job description\\nResponsibilities\\nIdentify va...  \n",
       "8  Job description\\nResponsibilities:\\nBuild NLP ...  \n",
       "9  Job description\\nBrief about the Role\\nThe Pla...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "##To open the web page in chrome driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "url=\" https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "#To get automated desired desiganation in search box\n",
    "search_job=driver.find_element_by_xpath('//input[@id=\"qsb-keyword-sugg\"]')\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "#To get automated desired location in search box\n",
    "search_loc=driver.find_element_by_xpath('//input[@id=\"qsb-location-sugg\"]')\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "#To click on search buton\n",
    "button_tag=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "button_tag.click()\n",
    "time.sleep(3)\n",
    "#To scrap the job title from the landing page.\n",
    "job_tag=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_tag_title=[]\n",
    "for i in job_tag[0:10]:\n",
    "    job_tag_title.append(i.text)\n",
    "time.sleep(2)\n",
    "#To scrap the job location from the landing page.\n",
    "location_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "location=[]\n",
    "for i in location_tag[0:10]:\n",
    "    location.append(i.text)\n",
    "time.sleep(3)\n",
    "#To fetch the company name from the page.\n",
    "company_tag=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_name=[]\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "#To wait to run next code till 3 second\n",
    "time.sleep(3)\n",
    "#To fetch job title element from web page after desired search criteria executed\n",
    "job_title=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "#Initiating for loop, for click on job title and fetching job description after opened new window.\n",
    "job_desc=[]   \n",
    "for i in job_title[0:11]:\n",
    "    i.click()\n",
    "    time.sleep(3)\n",
    "    #p=driver.current_window_handle\n",
    "    chwd=driver.window_handles\n",
    "    #switch window to fetch job description after clicking on job title.\n",
    "    time.sleep(2)\n",
    "    driver.switch_to.window(chwd[1])\n",
    "    #Now to fetch jobs tags element for job description by for loop\n",
    "    job_tags=driver.find_elements_by_xpath('//section[@class=\"job-desc\"]')\n",
    "    for j in job_tags:\n",
    "        time.sleep(1)\n",
    "        job_desc.append(j.text)\n",
    "        break\n",
    "    driver.close()\n",
    "    driver.switch_to.window(chwd[0])\n",
    "\n",
    "#Creating dectionary for required result\n",
    "search_data={\"Job Title\":job_tag_title,\n",
    "            \"Job Location\":location,\n",
    "            \"Company Name\":company_name,\n",
    "            \"Job Description\":job_desc}\n",
    "\n",
    "\n",
    "#To get data frame for first 10 job result\n",
    "job_result=pd.DataFrame(search_data)\n",
    "job_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:**\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Pune(Baner)</td>\n",
       "      <td>AlgoAnalytics Private Ltd.</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune(Hadapsar)</td>\n",
       "      <td>Springer Nature Technology and Publishing SOLU...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyst Data Scientist</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>CAMSDATA TECHNOLOGIES INDIA PVT LTD</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Machine Learning Engineer</td>\n",
       "      <td>Pune</td>\n",
       "      <td>PubMatic India Pvt. Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science- Associate Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Jet2 Travel Technologies Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Requirement For Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Credence HR Services</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Mumbai (All Areas)</td>\n",
       "      <td>Intellimation Market Services Limited</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist and Analyst</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineers /Data Scientist - CES IT LTD - ...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                           Associate Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                             Analyst Data Scientist   \n",
       "4         Data Scientist / Machine Learning Engineer   \n",
       "5             Data Science- Associate Data Scientist   \n",
       "6              Urgent Requirement For Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                         Data Scientist and Analyst   \n",
       "9  Data Engineers /Data Scientist - CES IT LTD - ...   \n",
       "\n",
       "                                        job Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                        Pune(Baner)   \n",
       "2                                     Pune(Hadapsar)   \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "4                                               Pune   \n",
       "5                                               Pune   \n",
       "6                                               Pune   \n",
       "7                           Pune, Mumbai (All Areas)   \n",
       "8                                               Pune   \n",
       "9  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "\n",
       "                                        Company Name Experience Required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                         AlgoAnalytics Private Ltd.             0-1 Yrs  \n",
       "2  Springer Nature Technology and Publishing SOLU...             3-6 Yrs  \n",
       "3                CAMSDATA TECHNOLOGIES INDIA PVT LTD             3-8 Yrs  \n",
       "4                           PubMatic India Pvt. Ltd.             2-7 Yrs  \n",
       "5                 Jet2 Travel Technologies Pvt. Ltd.             0-2 Yrs  \n",
       "6                               Credence HR Services             2-6 Yrs  \n",
       "7              Intellimation Market Services Limited             0-4 Yrs  \n",
       "8                                       Diverse Lynx             2-6 Yrs  \n",
       "9                                           CES Ltd.             3-5 Yrs  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "#To get automated desired desiganation in search box\n",
    "search_job=driver.find_element_by_xpath('//input[@id=\"qsb-keyword-sugg\"]')\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "#To click on search buton\n",
    "button_tag=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "button_tag.click()\n",
    "time.sleep(3)\n",
    "#To filter location and salary\n",
    "location_filter=driver.find_element_by_xpath('//span[text()=\"Pune\"]')\n",
    "location_filter.click()\n",
    "time.sleep(3)\n",
    "salary_filter=driver.find_element_by_xpath('//span[text()=\"3-6 Lakhs\"]')\n",
    "salary_filter.click()\n",
    "time.sleep(3)\n",
    "#To fetch job title description from the webpage\n",
    "job_tag=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_title=[]\n",
    "for i in job_tag[0:10]:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "#To fetch job location from the webpage\n",
    "job_loc_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "job_loc=[]\n",
    "for i in job_loc_tag[0:10]:\n",
    "    job_loc.append(i.text)\n",
    "\n",
    "#To fetch company name from the webpage\n",
    "company_tag=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_name=[]\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "#To fetch experiance details from the webpage\n",
    "exp_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "exp=[]\n",
    "for i in exp_tag[0:10]:\n",
    "    exp.append(i.text)\n",
    "\n",
    "result={\"Job Title\": job_title,\n",
    "       \"job Location\":job_loc,\n",
    "       \"Company Name\":company_name,\n",
    "       \"Experience Required\":exp}\n",
    "job_result=pd.DataFrame(result)\n",
    "job_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.**\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Aged</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uber</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uber</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cervello Inc</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MakeMyTrip</td>\n",
       "      <td>11d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Proziod Analytics</td>\n",
       "      <td>2d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Uber</td>\n",
       "      <td>19d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fidelity Investments</td>\n",
       "      <td>13d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wabtec</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Company Name Job Aged Company Rating\n",
       "0                                             Uber       4d            4.3\n",
       "1                                             Uber       4d            4.3\n",
       "2                                     Cervello Inc       3d            3.9\n",
       "3                                       MakeMyTrip      11d            4.3\n",
       "4  Siemens Technology and Services Private Limited       4d            4.1\n",
       "5                                Proziod Analytics       2d            4.3\n",
       "6                                             Uber      19d            4.3\n",
       "7                             Fidelity Investments      13d            4.2\n",
       "8                                           PayPal       9d            4.3\n",
       "9                                           Wabtec      24h            3.5"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "#To get the webpage\n",
    "url=\" https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "#To click in sign in option\n",
    "button_tag=driver.find_element_by_xpath('//html/body/div[2]/div/div/div/div/div[1]/article/header/nav/div[2]/div/div/div/button')\n",
    "button_tag.click()\n",
    "time.sleep(5)\n",
    "#To provide user name and password for login\n",
    "email_input=driver.find_element_by_id(\"userEmail\")\n",
    "email_input.send_keys(\"sudhansu@getgrowapp.com\")\n",
    "password_input=driver.find_element_by_id(\"userPassword\")\n",
    "password_input.send_keys(\"test@123\")\n",
    "#To click on Signin button\n",
    "signin_button=driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]')\n",
    "signin_button.click()\n",
    "time.sleep(2)\n",
    "#To search for job title and location with desired search word.\n",
    "search_job=driver.find_element_by_id(\"sc.keyword\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "time.sleep(1)\n",
    "search_loc=driver.find_element_by_id(\"sc.location\")\n",
    "#To delete the default value in location search bar\n",
    "search_loc.send_keys(Keys.CONTROL + \"a\")\n",
    "search_loc.send_keys(Keys.DELETE)\n",
    "search_loc.send_keys(\"Noida\")\n",
    "#To click on search button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr\"]')\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#To scrap company name data from web page\n",
    "com_name=driver.find_elements_by_xpath('//div[@class=\"d-flex justify-content-between align-items-start\"]')\n",
    "company_name=[]\n",
    "for i in com_name[0:10]:\n",
    "    company_name.append(i.text)\n",
    "#To scrap no. of days job posted\n",
    "job_age=driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')\n",
    "job_aged=[]\n",
    "for i in job_age[0:10]:\n",
    "    job_aged.append(i.text)\n",
    "\n",
    "#To scrap rating of the company\n",
    "rating=driver.find_elements_by_xpath('//span[@class=\"css-19pjha7 e1cjmv6j1\"]')\n",
    "comp_rating=[]\n",
    "for i in rating[0:10]:\n",
    "    comp_rating.append(i.text)\n",
    "\n",
    "#To sign out from the web site\n",
    "drop_down=driver.find_element_by_xpath('//div[@class=\"d-flex\"]')\n",
    "drop_down.click()\n",
    "time.sleep(3)\n",
    "sign_out_button=driver.find_element_by_xpath('//*[@id=\"SiteNav\"]/nav[1]/div/div/div/div[1]/div[2]/div/div[2]/div/div/div/div/div[1]/ul[4]/li[2]/a/div')\n",
    "sign_out_button.click()\n",
    "time.sleep(2)\n",
    "driver.close()\n",
    "\n",
    "\n",
    "\n",
    "#To put in data frame\n",
    "final_data={\"Company Name\":company_name,\n",
    "            \"Job Aged\":job_aged,\n",
    "          \"Company Rating\": comp_rating}\n",
    "search_result=pd.DataFrame(final_data)\n",
    "search_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5: Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.**\n",
    "\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page \n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company\n",
    "    name, Average salary and rating of the company.\n",
    "    6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It will show report only when rating column doesn't show in web page and so have not shown any rating data in below code becuase sometime rating columns shows and sometime it doesn't ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹27L</td>\n",
       "      <td>₹9,00,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,15,289/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹11,63,336/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,18,244/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹7,39,238/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹11L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹13,38,279/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹8,63,750/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹13,28,697/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹11,42,356/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹11,46,073/yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name Minimum Salary Maximum Salary Average Salary\n",
       "0                        IBM            ₹6L           ₹27L   ₹9,00,000/yr\n",
       "1  Tata Consultancy Services            ₹3L           ₹13L   ₹6,15,289/yr\n",
       "2                  Accenture            ₹6L           ₹22L  ₹11,63,336/yr\n",
       "3                  Delhivery            ₹5L           ₹1Cr  ₹12,18,244/yr\n",
       "4         Ericsson-Worldwide            ₹4L           ₹16L   ₹7,39,238/yr\n",
       "5         UnitedHealth Group           ₹11L           ₹15L  ₹13,38,279/yr\n",
       "6         Valiance Solutions            ₹5L           ₹15L   ₹8,63,750/yr\n",
       "7     Optum Global Solutions            ₹4L           ₹22L  ₹13,28,697/yr\n",
       "8              ZS Associates            ₹2L           ₹18L  ₹11,42,356/yr\n",
       "9                EXL Service            ₹6L           ₹15L  ₹11,46,073/yr"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\" https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "#To search for job title with desired search word.\n",
    "search_job=driver.find_element_by_id(\"KeywordSearch\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "time.sleep(3)\n",
    "#To search for location with desired search word.\n",
    "search_loc=driver.find_element_by_id(\"LocationSearch\")\n",
    "#To delete the default value in location search bar\n",
    "search_loc.send_keys(Keys.CONTROL + \"a\")\n",
    "search_loc.send_keys(Keys.DELETE)\n",
    "time.sleep(2)\n",
    "search_loc.send_keys(\"Noida\")\n",
    "#To click on search button\n",
    "search_button=driver.find_element_by_id(\"HeroSearchButton\")\n",
    "search_button.click()\n",
    "time.sleep(8)\n",
    "\n",
    "#To click on signin option on popup page\n",
    "new_window=driver.find_element_by_xpath('//*[@id=\"HardsellOverlay\"]/div/div/div[1]/div/div/div/div/div[2]/div/a')\n",
    "new_window.click()\n",
    "time.sleep(2)\n",
    "#To provide user name and password for login\n",
    "email_input=driver.find_element_by_id(\"userEmail\")\n",
    "email_input.send_keys(\"sudhansu@getgrowapp.com\")\n",
    "password_input=driver.find_element_by_id(\"userPassword\")\n",
    "password_input.send_keys(\"test@123\")\n",
    "#To click on Signin button\n",
    "signin_button=driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]')\n",
    "signin_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#To scrap company name\n",
    "comp_name=driver.find_elements_by_xpath('//p[@class=\"m-0 \"]')\n",
    "time.sleep(5)\n",
    "company_name=[]\n",
    "for i in comp_name[0:10]:\n",
    "    company_name.append(i.text)\n",
    "time.sleep(5)\n",
    "\n",
    "#To scrap min and max salary\n",
    "salary=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]')\n",
    "time.sleep(5)\n",
    "\n",
    "salary_list=[]\n",
    "for i in salary[0:10]:\n",
    "    salary_list.append(i.text)\n",
    "#Removing \"\\n\" from list of string.\n",
    "new_salary_list = [(s.replace(\"\\n\", \",\")).split(\",\") for s in salary_list]\n",
    "time.sleep(3)\n",
    "#Seperating min and max salary from list\n",
    "salary_min=[]\n",
    "salary_max=[]\n",
    "j=0\n",
    "k=1\n",
    "for i in new_salary_list:\n",
    "    salary_min.append(i[0])\n",
    "    salary_max.append(i[1])\n",
    "    \n",
    "time.sleep(3)\n",
    "#To scrap the Average Salary from the web page\n",
    "avg_salary=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]')\n",
    "time.sleep(3)\n",
    "average_sal=[]\n",
    "for i in avg_salary[0:10]:\n",
    "    average_sal.append(i.text)\n",
    "average_salary=[(a.replace(\"\\n\",\"\")) for a in average_sal]\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "result={'Company Name':company_name,\n",
    "        \"Minimum Salary\":salary_min,\n",
    "        \"Maximum Salary\":salary_max,\n",
    "        \"Average Salary\":average_salary,\n",
    "        }\n",
    "\n",
    "data_result=pd.DataFrame(result)\n",
    "   \n",
    "\n",
    "#To sign out from the web site\n",
    "drop_down=driver.find_element_by_xpath('//div[@class=\"d-flex\"]')\n",
    "drop_down.click()\n",
    "time.sleep(3)\n",
    "sign_out_button=driver.find_element_by_xpath('//*[@id=\"SiteNav\"]/nav[1]/div/div/div/div[1]/div[2]/div/div[2]/div/div/div/div/div[1]/ul[4]/li[2]/a/div')\n",
    "sign_out_button.click()\n",
    "time.sleep(2)\n",
    "driver.close()\n",
    "#To show data table\n",
    "data_result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If rating is showing in our web page then this report will shows sucessfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹27L</td>\n",
       "      <td>₹9,00,000 /yr</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,15,289 /yr</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹11,63,336 /yr</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,18,244 /yr</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹7,39,238 /yr</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹11L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹13,38,279 /yr</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹8,63,750 /yr</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹13,28,697 /yr</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹11,42,356 /yr</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹11,46,073 /yr</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name Minimum Salary Maximum Salary  Average Salary  \\\n",
       "0                        IBM            ₹6L           ₹27L   ₹9,00,000 /yr   \n",
       "1  Tata Consultancy Services            ₹3L           ₹13L   ₹6,15,289 /yr   \n",
       "2                  Accenture            ₹6L           ₹22L  ₹11,63,336 /yr   \n",
       "3                  Delhivery            ₹5L           ₹1Cr  ₹12,18,244 /yr   \n",
       "4         Ericsson-Worldwide            ₹4L           ₹16L   ₹7,39,238 /yr   \n",
       "5         UnitedHealth Group           ₹11L           ₹15L  ₹13,38,279 /yr   \n",
       "6         Valiance Solutions            ₹5L           ₹15L   ₹8,63,750 /yr   \n",
       "7     Optum Global Solutions            ₹4L           ₹22L  ₹13,28,697 /yr   \n",
       "8              ZS Associates            ₹2L           ₹18L  ₹11,42,356 /yr   \n",
       "9                EXL Service            ₹6L           ₹15L  ₹11,46,073 /yr   \n",
       "\n",
       "  Company Rating  \n",
       "0            3.9  \n",
       "1            3.9  \n",
       "2              4  \n",
       "3            3.9  \n",
       "4              4  \n",
       "5            3.7  \n",
       "6            4.2  \n",
       "7            3.9  \n",
       "8              4  \n",
       "9            3.6  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\" https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "#To search for job title with desired search word.\n",
    "search_job=driver.find_element_by_id(\"KeywordSearch\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "time.sleep(3)\n",
    "#To search for location with desired search word.\n",
    "search_loc=driver.find_element_by_id(\"LocationSearch\")\n",
    "#To delete the default value in location search bar\n",
    "search_loc.send_keys(Keys.CONTROL + \"a\")\n",
    "search_loc.send_keys(Keys.DELETE)\n",
    "time.sleep(2)\n",
    "search_loc.send_keys(\"Noida\")\n",
    "#To click on search button\n",
    "search_button=driver.find_element_by_id(\"HeroSearchButton\")\n",
    "search_button.click()\n",
    "time.sleep(8)\n",
    "\n",
    "#To click on signin option on popup page\n",
    "new_window=driver.find_element_by_xpath('//*[@id=\"HardsellOverlay\"]/div/div/div[1]/div/div/div/div/div[2]/div/a')\n",
    "new_window.click()\n",
    "time.sleep(2)\n",
    "#To provide user name and password for login\n",
    "email_input=driver.find_element_by_id(\"userEmail\")\n",
    "email_input.send_keys(\"sudhansu@getgrowapp.com\")\n",
    "password_input=driver.find_element_by_id(\"userPassword\")\n",
    "password_input.send_keys(\"test@123\")\n",
    "#To click on Signin button\n",
    "signin_button=driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]')\n",
    "signin_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#To scrap company name\n",
    "comp_name=driver.find_elements_by_xpath('//a[@class=\"css-f3vw95 e1aj7ssy3\"]')\n",
    "time.sleep(5)\n",
    "company_name=[]\n",
    "for i in comp_name[0:10]:\n",
    "    company_name.append(i.text)\n",
    "time.sleep(5)\n",
    "\n",
    "#To scrap min and max salary\n",
    "salary=driver.find_elements_by_xpath('//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]')\n",
    "time.sleep(5)\n",
    "\n",
    "salary_list=[]\n",
    "for i in salary[0:10]:\n",
    "    salary_list.append(i.text)\n",
    "#Removing \"\\n\" from list of string.\n",
    "new_salary_list = [(s.replace(\"\\n\", \",\")).split(\",\") for s in salary_list]\n",
    "time.sleep(3)\n",
    "#Seperating min and max salary from list\n",
    "salary_min=[]\n",
    "salary_max=[]\n",
    "j=0\n",
    "k=1\n",
    "for i in new_salary_list:\n",
    "    salary_min.append(i[0])\n",
    "    salary_max.append(i[1])\n",
    "    \n",
    "time.sleep(3)\n",
    "#To scrap the Average Salary from the web page\n",
    "avg_salary=driver.find_elements_by_xpath('//div[@class=\"col-12 col-lg-4 px-lg-0 d-flex align-items-baseline\"]')\n",
    "time.sleep(3)\n",
    "average_sal=[]\n",
    "for i in avg_salary[0:10]:\n",
    "    average_sal.append(i.text)\n",
    "average_salary=[(a.replace(\"\\n\",\"\")) for a in average_sal]\n",
    "\n",
    "time.sleep(5)\n",
    "#To scrap the rating of the company\n",
    "company_rat=driver.find_elements_by_xpath('//span[@class=\"m-0 css-kyx745\"]')\n",
    "time.sleep(3)\n",
    "company_rating=[]\n",
    "for i in company_rat[0:10]:\n",
    "    company_rating.append(i.text)\n",
    "time.sleep(3)    \n",
    "\n",
    "result={'Company Name':company_name,\n",
    "        \"Minimum Salary\":salary_min,\n",
    "        \"Maximum Salary\":salary_max,\n",
    "        \"Average Salary\":average_salary,\n",
    "        \"Company Rating\":company_rating}\n",
    "\n",
    "data_result=pd.DataFrame(result)\n",
    "     \n",
    "\n",
    "#To sign out from the web site\n",
    "drop_down=driver.find_element_by_xpath('//div[@class=\"d-flex\"]')\n",
    "drop_down.click()\n",
    "time.sleep(3)\n",
    "sign_out_button=driver.find_element_by_xpath('//*[@id=\"SiteNav\"]/nav[1]/div/div/div/div[1]/div[2]/div/div[2]/div/div/div/div/div[1]/ul[4]/li[2]/a/div')\n",
    "sign_out_button.click()\n",
    "time.sleep(2)\n",
    "driver.close()\n",
    "\n",
    "#To show data table\n",
    "data_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:**\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %**\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Price</th>\n",
       "      <th>Product Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EYELLUSION</td>\n",
       "      <td>Night Vision, Polarized, UV Protection, Riding...</td>\n",
       "      <td>₹351</td>\n",
       "      <td>₹1948 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹1,273</td>\n",
       "      <td>₹726 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>₹2300 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>₹286 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹587</td>\n",
       "      <td>₹312 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>hipe</td>\n",
       "      <td>Mirrored, UV Protection, Gradient Round Sungla...</td>\n",
       "      <td>₹210</td>\n",
       "      <td>₹3209 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>FOSSIL</td>\n",
       "      <td>Others Rectangular Sunglasses (52)</td>\n",
       "      <td>₹1,191</td>\n",
       "      <td>₹145 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹1,854</td>\n",
       "      <td>₹442 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹457</td>\n",
       "      <td>₹810 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Gradient, Night Vision, Mirrore...</td>\n",
       "      <td>₹365</td>\n",
       "      <td>₹1220 off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description  \\\n",
       "0       EYELLUSION  Night Vision, Polarized, UV Protection, Riding...   \n",
       "1    VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "2   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "4         Fastrack       UV Protection Aviator Sunglasses (Free Size)   \n",
       "..             ...                                                ...   \n",
       "95            hipe  Mirrored, UV Protection, Gradient Round Sungla...   \n",
       "96          FOSSIL                 Others Rectangular Sunglasses (52)   \n",
       "97        Fastrack       UV Protection Aviator Sunglasses (Free Size)   \n",
       "98        Fastrack             UV Protection Wayfarer Sunglasses (56)   \n",
       "99           NuVew  UV Protection, Gradient, Night Vision, Mirrore...   \n",
       "\n",
       "   Product Price Product Discount  \n",
       "0           ₹351        ₹1948 off  \n",
       "1         ₹1,273         ₹726 off  \n",
       "2           ₹299        ₹2300 off  \n",
       "3           ₹513         ₹286 off  \n",
       "4           ₹587         ₹312 off  \n",
       "..           ...              ...  \n",
       "95          ₹210        ₹3209 off  \n",
       "96        ₹1,191         ₹145 off  \n",
       "97        ₹1,854         ₹442 off  \n",
       "98          ₹457         ₹810 off  \n",
       "99          ₹365        ₹1220 off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\" https://www.flipkart.com\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#To close the pop-up \n",
    "cross_button=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "cross_button.click()\n",
    "#To search with desired text in search box\n",
    "search_prod=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_prod.send_keys(\"sunglasses\")\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Total page no in flipkart.\n",
    "total_page=driver.find_element_by_xpath('//div[@class=\"_2MImiq\"]')\n",
    "max_page=int((((total_page.text).split(\",\"))[1])[0:3])\n",
    "max_page \n",
    "\n",
    "#To scrap brand name,product description,price and discount for required pages from websites\n",
    "brand_name=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "max_page=3 # given less page number for computional benefit.\n",
    "\n",
    "for i in range(1,max_page+1):\n",
    "    url=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(i)\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    brand_content=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    time.sleep(2)\n",
    "    for ele in brand_content:\n",
    "        brand_name.append(ele.text)\n",
    "     \n",
    "    product_content=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    time.sleep(3)\n",
    "    for ele in product_content:\n",
    "        product_desc.append(ele.text)\n",
    "    \n",
    "    \n",
    "    price_content=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    time.sleep(2)\n",
    "    for ele in price_content:\n",
    "        price.append(ele.text)\n",
    "    \n",
    "    \n",
    "    discount_content=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    time.sleep(2)\n",
    "    for ele in discount_content:\n",
    "        discount.append(ele.text)\n",
    "\n",
    "        \n",
    "Data={\"Brand Name\":brand_name,\n",
    "     \"Product Description\":product_desc,\n",
    "     \"Product Price\":price,\n",
    "     \"Product Discount\":discount}\n",
    "    \n",
    "Report=pd.DataFrame(dict([(j,pd.Series(i))for j,i in Data.items()]))\n",
    "Report[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to\n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.**\n",
    "\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Value for money product. This iphone 11 is rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>The best all rounder iphone. Flipkart is doing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>I genuinely liked it. One of the best mobile p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>If you are looking for a premium phone under 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>Awesome camera, smooth and fast UI, display is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                Review  \\\n",
       "0       5             Brilliant   \n",
       "1       5      Perfect product!   \n",
       "2       5             Fabulous!   \n",
       "3       5     Worth every penny   \n",
       "4       5         Great product   \n",
       "..    ...                   ...   \n",
       "95      4             Excellent   \n",
       "96      4   Best in the market!   \n",
       "97      4             Wonderful   \n",
       "98    NaN          Nice product   \n",
       "99    NaN  Good quality product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   This is my first iOS phone. I am very happy wi...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "..                                                ...  \n",
       "95  Value for money product. This iphone 11 is rea...  \n",
       "96  The best all rounder iphone. Flipkart is doing...  \n",
       "97  I genuinely liked it. One of the best mobile p...  \n",
       "98  If you are looking for a premium phone under 5...  \n",
       "99  Awesome camera, smooth and fast UI, display is...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#To click on all review to get access of review\n",
    "all_review_button=driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]')\n",
    "all_review_button.click()\n",
    "\n",
    "\n",
    "#To scrap rating,review summary and full review\n",
    "\n",
    "max_page=10 # given less page number for computional benefit.\n",
    "\n",
    "rating_details=[]\n",
    "review_details=[]\n",
    "full_review=[]\n",
    "for i in range(1,max_page+1):\n",
    "    url1=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(i)\n",
    "    driver.get(url1)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    rating_cont=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    time.sleep(2)\n",
    "    for i in rating_cont:\n",
    "        rating_details.append(i.text)\n",
    "        \n",
    "    review_cont=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    time.sleep(1)\n",
    "    for i in review_cont:\n",
    "        review_details.append(i.text)\n",
    "        \n",
    "    full_review_cont=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    time.sleep(1)\n",
    "    for i in full_review_cont:\n",
    "        full_review.append(i.text)\n",
    "        \n",
    "data={\"Rating\":rating_details,\n",
    "     \"Review\":review_details,\n",
    "     \"Full Review\":full_review}\n",
    "\n",
    "Result=pd.DataFrame(dict([(i,pd.Series(v)) for i,v in data.items()]))\n",
    "Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.**\n",
    "\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Also note that all the steps required during scraping should be done through code\n",
    "only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Price</th>\n",
       "      <th>Product Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India hub</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹410</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shoes Bank</td>\n",
       "      <td>Series 7 Sneakers For Men</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>casual for men (blue 06) Sneakers For Men</td>\n",
       "      <td>₹416</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Echor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹539</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹669</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹999</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>NIKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹2,472</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Absolute comfort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹348</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name                                    Product Name  \\\n",
       "0             Numenzo                                Sneakers For Men   \n",
       "1           India hub  White Sneaker For Men's/Boy's Sneakers For Men   \n",
       "2          Shoes Bank                       Series 7 Sneakers For Men   \n",
       "3            CALCADOS  Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4              Kraasa       casual for men (blue 06) Sneakers For Men   \n",
       "..                ...                                             ...   \n",
       "75              Echor                                             NaN   \n",
       "76  French Connection                                             NaN   \n",
       "77             DUCATI                                             NaN   \n",
       "78               NIKE                                             NaN   \n",
       "79   Absolute comfort                                             NaN   \n",
       "\n",
       "   Product Price Product Discount  \n",
       "0           ₹449          77% off  \n",
       "1           ₹410          86% off  \n",
       "2           ₹349          65% off  \n",
       "3           ₹748          62% off  \n",
       "4           ₹416          58% off  \n",
       "..           ...              ...  \n",
       "75          ₹539          46% off  \n",
       "76          ₹669          76% off  \n",
       "77          ₹999          72% off  \n",
       "78        ₹2,472          45% off  \n",
       "79          ₹348          65% off  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#To search for desired from search bar\n",
    "search_content=driver.find_element_by_xpath('//input[@type=\"text\"]')\n",
    "search_content.send_keys(\"sneakers\")\n",
    "#To click on button\n",
    "click_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "click_button.click()\n",
    "\n",
    "#To fetch brand,product Description,price and discount from the web page\n",
    "brand_name=[]\n",
    "product_name=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "page=2\n",
    "for i in range(1,page+1):\n",
    "    url1=\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(i)\n",
    "    driver.get(url1)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    brand_cont=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_cont:\n",
    "        brand_name.append(i.text)\n",
    "        \n",
    "    product_cont=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_cont:\n",
    "        product_name.append(i.text)\n",
    "        \n",
    "    price_cont=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_cont:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    discount_cont=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in discount_cont:\n",
    "        discount.append(i.text)\n",
    "\n",
    "data={\"Brand Name\":brand_name,\n",
    "     \"Product Name\":product_name,\n",
    "     \"Product Price\":price,\n",
    "     \"Product Discount\":discount}\n",
    "Report=pd.DataFrame(dict([(k,pd.Series(v)) for k,v in data.items()]))\n",
    "Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in\n",
    "the below image**\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be\n",
    "done through code only and there should not be any manual step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Brands data from web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nike',\n",
       " 'Nike',\n",
       " 'ALDO',\n",
       " 'Nike',\n",
       " 'Nike',\n",
       " 'Nike',\n",
       " 'Nike',\n",
       " 'Nike',\n",
       " 'Nike',\n",
       " 'Nike',\n",
       " 'UNDER ARMOUR',\n",
       " 'ASICS',\n",
       " 'PUMA Motorsport',\n",
       " 'Puma',\n",
       " 'UNDER ARMOUR',\n",
       " 'UNDER ARMOUR',\n",
       " 'UNDER ARMOUR',\n",
       " 'J.FONTINI',\n",
       " 'ADIDAS',\n",
       " 'UNDER ARMOUR',\n",
       " 'ASICS',\n",
       " 'Puma',\n",
       " 'Cole Haan',\n",
       " 'FORCLAZ By Decathlon',\n",
       " 'UNDER ARMOUR',\n",
       " 'Hush Puppies',\n",
       " 'Hush Puppies',\n",
       " 'Ruosh',\n",
       " 'Geox',\n",
       " 'UNDER ARMOUR',\n",
       " 'UNDER ARMOUR',\n",
       " 'Hush Puppies',\n",
       " 'UNDER ARMOUR',\n",
       " 'Bugatti',\n",
       " 'ASICS',\n",
       " 'UNDER ARMOUR',\n",
       " 'Puma',\n",
       " 'Bugatti',\n",
       " 'Nike',\n",
       " 'J.FONTINI',\n",
       " 'Hush Puppies',\n",
       " 'J.FONTINI',\n",
       " 'Hush Puppies',\n",
       " 'Kalenji By Decathlon',\n",
       " 'Hush Puppies',\n",
       " 'Hush Puppies',\n",
       " 'Hush Puppies',\n",
       " 'DAVINCHI',\n",
       " 'RARE RABBIT',\n",
       " 'Bugatti',\n",
       " 'Bugatti',\n",
       " 'Cole Haan',\n",
       " 'ALDO',\n",
       " 'UNDER ARMOUR',\n",
       " 'FILA',\n",
       " 'Ruosh',\n",
       " 'UNDER ARMOUR',\n",
       " 'Heel & Buckle London',\n",
       " 'RARE RABBIT',\n",
       " 'Cole Haan',\n",
       " 'Saint G',\n",
       " 'UNDER ARMOUR',\n",
       " 'ADIDAS',\n",
       " 'Geox',\n",
       " 'Bugatti',\n",
       " 'Geox',\n",
       " 'Reebok',\n",
       " 'Quechua By Decathlon',\n",
       " 'Geox',\n",
       " 'UNDER ARMOUR',\n",
       " 'Cole Haan',\n",
       " 'Cole Haan',\n",
       " 'Geox',\n",
       " 'Puma',\n",
       " 'FILA',\n",
       " 'UNDER ARMOUR',\n",
       " 'VIONIC',\n",
       " 'J.FONTINI',\n",
       " 'Puma',\n",
       " 'Geox',\n",
       " 'Heel & Buckle London',\n",
       " 'Saint G',\n",
       " 'Saint G',\n",
       " 'Reebok',\n",
       " 'Cole Haan',\n",
       " 'Geox',\n",
       " 'Heel & Buckle London',\n",
       " 'Cole Haan',\n",
       " 'ADIDAS',\n",
       " 'Nike',\n",
       " 'Nike',\n",
       " 'Heel & Buckle London',\n",
       " 'Nike',\n",
       " 'Hush Puppies',\n",
       " 'Skechers',\n",
       " 'UNDER ARMOUR',\n",
       " 'Nike',\n",
       " 'Heel & Buckle London',\n",
       " 'FILA',\n",
       " 'Geox']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#To apply price filter and color filter\n",
    "price_filter=driver.find_element_by_xpath('//html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]')\n",
    "price_filter.click()\n",
    "time.sleep(2)\n",
    "color_filter=driver.find_element_by_xpath('//li[@class=\"colour-listItem\"]')\n",
    "color_filter.click()\n",
    "\n",
    "#Update page number\n",
    "page=2\n",
    "\n",
    "#To fetch brand details from different pages\n",
    "a=1\n",
    "shoe_brand=[]\n",
    "brand_ele=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "for i in range(1,page+1):\n",
    "    time.sleep(3)\n",
    "    brand_ele=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    time.sleep(10)\n",
    "    for ele in brand_ele[0:50]:\n",
    "        shoe_brand.append(ele.text)\n",
    "        a+=1      \n",
    "    if a==51:\n",
    "        next_b=driver.find_element_by_xpath('//a[@rel=\"next\"]')\n",
    "        next_b.click()\n",
    "driver.close()\n",
    "shoe_brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Shoes Description data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men Zoom Winflo 8 Running',\n",
       " 'Men AIR ZOOM PEGASUS 38 Run',\n",
       " 'Men JORDAN WHY NOT Basketball',\n",
       " 'Men Sneakers',\n",
       " 'Men REACT MILER Running Shoes',\n",
       " 'Men JOYRIDE Running Shoes',\n",
       " 'Men AIR ZOOM Running Shoes',\n",
       " 'Men KD13 EP Basketball Shoes',\n",
       " 'AIR ZOOM PEGASUS Running Shoes',\n",
       " 'HOVR Sonic 3 Running Shoes',\n",
       " 'Unisex LEBRON XVIII Basketball',\n",
       " 'Women Running Shoes',\n",
       " 'Unisex Mercedes Running Shoes',\n",
       " 'Men Velocity Nitro Running',\n",
       " 'Women Charged Breathe TR 2',\n",
       " 'Women Liquify Rebel Running',\n",
       " 'Men Liquify Running Shoes',\n",
       " 'Men SOLAR DRIVE 19 M Running',\n",
       " 'Unisex SC 3ZER0 IV Basketball',\n",
       " 'Women Running Shoes',\n",
       " 'Leather Sneakers',\n",
       " 'TREKKING 100 Boots',\n",
       " 'Women Deviate Nitro Running',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Women HOVR Rise 2 Training',\n",
       " 'Men Leather Slip-On Sneakers',\n",
       " 'Men Leather Slip-On Shoes',\n",
       " 'Men Solid Leather Formal Oxfords',\n",
       " 'Men Leather Driving Shoes',\n",
       " 'Charged Rogue 2 Wide 2E Shoes',\n",
       " 'Men HOVR Infinite Running',\n",
       " 'Men Solid Leather Formal Slip-Ons',\n",
       " 'Women TriBase Reign 2 Training',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Charged Impulse Running Shoes',\n",
       " 'Women Velocity Nitro Running',\n",
       " 'Men Slip-On Sneakers',\n",
       " 'Men Running Shoes',\n",
       " 'Men JORDAN DELTA Sneakers',\n",
       " 'Men Solid Loafers',\n",
       " 'Men Leather Slip-On Sneakers',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Men Textured Oxfords',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Men Formal Derbys',\n",
       " 'Men KD500 Running Shoe',\n",
       " 'Men Solid Leather Formal Slip-Ons',\n",
       " 'Men Textured Formal Leather Loafers',\n",
       " 'Men Textured Leather Formal Loafers',\n",
       " 'Women Solid Leather Ballerinas',\n",
       " 'Women Solid Leather Ballerinas',\n",
       " 'Women Sandals',\n",
       " 'Women Charged Breathe OIL SLK',\n",
       " 'Men Formal Leather Brogues',\n",
       " 'HOVR Sonic 3 Running Shoes',\n",
       " 'Women Solid Leather Gladiators',\n",
       " 'Men Leather Loafers',\n",
       " 'Women Leather Sneakers',\n",
       " 'Women Solid Leather Pumps',\n",
       " 'Men Leather Sneakers',\n",
       " 'Women SUPERNOVA Running Shoes',\n",
       " 'Charged RC Sportstyle Sneakers',\n",
       " 'Men Perforations Leather Brogues',\n",
       " 'Women Leather Ballerinas',\n",
       " 'Women Mid-Top Sneakers',\n",
       " 'Women Solid Leather Loafers',\n",
       " 'Forever Floatride Energy 2',\n",
       " 'Men Trekking Shoes',\n",
       " 'Men Leather Driving Shoes',\n",
       " 'Charged Pursuit 2 Running',\n",
       " 'Men Wingtip Oxford Sneakers',\n",
       " 'Men GENERATION ZEROGRAND STITCHLITE',\n",
       " 'Men Leather Slip-On Sneakers',\n",
       " 'Men Football Shoes',\n",
       " 'Men Leather Sneakers',\n",
       " 'Women Charged Rogue 2 Running',\n",
       " 'Men Textured Sneakers',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Men IGNITE Dual Running Shoes',\n",
       " 'Men Leather Formal Monks',\n",
       " 'Women Solid Leather Heels',\n",
       " 'Women Leather Heeled Boots',\n",
       " 'Women Heeled Boots',\n",
       " 'Women Nanoflex Training Shoes',\n",
       " 'Women Leather Heels',\n",
       " 'Women Solid Leather Pumps',\n",
       " 'Women Peep Toe Heels',\n",
       " 'Women Open Toe Flats',\n",
       " 'Men Ultra Boost 21 Running',\n",
       " 'Men AIR ZOOM PEGASUS 38 Run',\n",
       " 'Men JORDAN ONE TAKE II Shoes',\n",
       " 'Men Leather Formal Oxfords',\n",
       " 'Men ZOOM WINFLO8 Running Shoes',\n",
       " 'SKECH-AIR ELEMENT Sneakers',\n",
       " 'Charged Pursuit 2 Running',\n",
       " 'Men REACT MILER 2 Running',\n",
       " 'Women Leather Pumps',\n",
       " 'Women Sneakers',\n",
       " 'Women Woven Design Slip-On Sneakers',\n",
       " 'Men Formal Leather Derbys']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#To apply price filter and color filter\n",
    "price_filter=driver.find_element_by_xpath('//html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]')\n",
    "price_filter.click()\n",
    "time.sleep(2)\n",
    "color_filter=driver.find_element_by_xpath('//li[@class=\"colour-listItem\"]')\n",
    "color_filter.click()\n",
    "\n",
    "#Update page number\n",
    "page=2\n",
    "\n",
    "#To fetch product description from different pages\n",
    "a=1\n",
    "shoe_desc=[]\n",
    "desc_ele=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "for i in range(1,page+1):\n",
    "    time.sleep(3)\n",
    "    desc_ele=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    time.sleep(10)\n",
    "    for ele in desc_ele[0:50]:\n",
    "        shoe_desc.append(ele.text)\n",
    "        a+=1      \n",
    "    if a==51:\n",
    "        next_b=driver.find_element_by_xpath('//a[@rel=\"next\"]')\n",
    "        next_b.click()\n",
    "\n",
    "driver.close()\n",
    "shoe_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Shoes price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 8295',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 11495',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7696Rs. 10995(30% OFF)',\n",
       " 'Rs. 7497Rs. 14995(50% OFF)',\n",
       " 'Rs. 7721Rs. 10295(25% OFF)',\n",
       " 'Rs. 12995',\n",
       " 'Rs. 11495',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 10557Rs. 17595( 40 % OFF)',\n",
       " 'Rs. 6999Rs. 9999(30% OFF)',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7149Rs. 10999(35% OFF)',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7799Rs. 11999(35% OFF)',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9799Rs. 13999(30% OFF)',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 9749Rs. 14999(35% OFF)',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999Rs. 9999(30% OFF)',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8094Rs. 13490(40% OFF)',\n",
       " 'Rs. 9990',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7149Rs. 10999(35% OFF)',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6999Rs. 9999(30% OFF)',\n",
       " 'Rs. 10995',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7857Rs. 8449(7% OFF)',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9799Rs. 13999(30% OFF)',\n",
       " 'Rs. 8119Rs. 11599(30% OFF)',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9799Rs. 13999(30% OFF)',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7490',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6993Rs. 9990(30% OFF)',\n",
       " 'Rs. 7699Rs. 10999(30% OFF)',\n",
       " 'Rs. 6622Rs. 8600(23% OFF)',\n",
       " 'Rs. 6999Rs. 9999(30% OFF)',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9490',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 9490',\n",
       " 'Rs. 8499Rs. 16999(50% OFF)',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7039Rs. 10999(36% OFF)',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7690',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7999Rs. 15999(50% OFF)',\n",
       " 'Rs. 6993Rs. 9990(30% OFF)',\n",
       " 'Rs. 6675Rs. 8900(25% OFF)',\n",
       " 'Rs. 7440Rs. 8000(7% OFF)',\n",
       " 'Rs. 7599',\n",
       " 'Rs. 6749Rs. 14999(55% OFF)',\n",
       " 'Rs. 10990',\n",
       " 'Rs. 7192Rs. 8990(20% OFF)',\n",
       " 'Rs. 8399Rs. 11999(30% OFF)',\n",
       " 'Rs. 12599Rs. 17999(30% OFF)',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 8295',\n",
       " 'Rs. 7693Rs. 10990(30% OFF)',\n",
       " 'Rs. 8295',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11495',\n",
       " 'Rs. 7192Rs. 8990(20% OFF)',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 11990']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#To apply price filter and color filter\n",
    "price_filter=driver.find_element_by_xpath('//html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]')\n",
    "price_filter.click()\n",
    "time.sleep(5)\n",
    "color_filter=driver.find_element_by_xpath('//li[@class=\"colour-listItem\"]')\n",
    "color_filter.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#Update page number\n",
    "page=2\n",
    "\n",
    "#To fetch product price from different pages\n",
    "a=1\n",
    "price_desc=[]\n",
    "price_ele=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "\n",
    "for i in range(1,page+1):\n",
    "    time.sleep(5)\n",
    "    price_ele=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    \n",
    "    for ele in price_ele[0:50]:\n",
    "        price_desc.append(ele.text)\n",
    "        a+=1\n",
    "    time.sleep(10)\n",
    "    if a==51:\n",
    "        next_b=driver.find_element_by_xpath('//a[@rel=\"next\"]')\n",
    "        next_b.click()\n",
    "        \n",
    "driver.close()\n",
    "price_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************Products Details in Table*************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe's Brand Name</th>\n",
       "      <th>Shoe's Description</th>\n",
       "      <th>Shoe's Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Winflo 8 Running</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM PEGASUS 38 Run</td>\n",
       "      <td>Rs. 9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men JORDAN WHY NOT Basketball</td>\n",
       "      <td>Rs. 11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER Running Shoes</td>\n",
       "      <td>Rs. 7696Rs. 10995(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men REACT MILER 2 Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Woven Design Slip-On Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Formal Leather Derbys</td>\n",
       "      <td>Rs. 11990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Shoe's Brand Name                   Shoe's Description  \\\n",
       "0                   Nike            Men Zoom Winflo 8 Running   \n",
       "1                   Nike          Men AIR ZOOM PEGASUS 38 Run   \n",
       "2                   ALDO        Men JORDAN WHY NOT Basketball   \n",
       "3                   Nike                         Men Sneakers   \n",
       "4                   Nike        Men REACT MILER Running Shoes   \n",
       "..                   ...                                  ...   \n",
       "95          UNDER ARMOUR            Men REACT MILER 2 Running   \n",
       "96                  Nike                  Women Leather Pumps   \n",
       "97  Heel & Buckle London                       Women Sneakers   \n",
       "98                  FILA  Women Woven Design Slip-On Sneakers   \n",
       "99                  Geox            Men Formal Leather Derbys   \n",
       "\n",
       "                  Shoe's Price  \n",
       "0                     Rs. 8295  \n",
       "1                     Rs. 9995  \n",
       "2                    Rs. 11495  \n",
       "3                     Rs. 9999  \n",
       "4   Rs. 7696Rs. 10995(30% OFF)  \n",
       "..                         ...  \n",
       "95                    Rs. 6999  \n",
       "96                   Rs. 11495  \n",
       "97   Rs. 7192Rs. 8990(20% OFF)  \n",
       "98                    Rs. 8999  \n",
       "99                   Rs. 11990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preparing into data frame\n",
    "data={\"Shoe's Brand Name\":shoe_brand,\n",
    "     \"Shoe's Description\":shoe_desc,\n",
    "     \"Shoe's Price\":price_desc}\n",
    "shoe_data=pd.DataFrame(dict([(i,pd.Series(v))for i,v in data.items()]))\n",
    "\n",
    "print(\"*******************Products Details in Table*************************\")\n",
    "shoe_data[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the\n",
    "below image:**\n",
    "    \n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Product Rating</th>\n",
       "      <th>Product Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "      <td>Price: ₹ 78,993.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>Price: ₹ 84,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>Combo Price: ₹ 59,999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>Price: ₹ 86,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>Price: ₹ 89,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>Price: ₹ 97,221.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "      <td>Price: ₹ 40,932.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSI GE75 Raider 10SFS 17.3\" FHD Gaming Laptop ...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>Price: ₹ 1,79,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell G3 3579 15.6-inch FHD Gaming Laptop (8th ...</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "      <td>Price: ₹ 89,898.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS ROG Zephyrus S17 (2020), 17.3\" FHD 300Hz/...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>Price: ₹ 1,37,990.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Product Title Product Rating  \\\n",
       "0  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...   3.9 out of 5   \n",
       "1  HP Pavilion (2021) Thin & Light 11th Gen Core ...   4.5 out of 5   \n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...   4.4 out of 5   \n",
       "3  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...   4.2 out of 5   \n",
       "4  Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...     4 out of 5   \n",
       "5  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...   4.3 out of 5   \n",
       "6  Life Digital Laptop 15.6-inch (39.62 cms) (Int...   3.7 out of 5   \n",
       "7  MSI GE75 Raider 10SFS 17.3\" FHD Gaming Laptop ...     5 out of 5   \n",
       "8  Dell G3 3579 15.6-inch FHD Gaming Laptop (8th ...   3.9 out of 5   \n",
       "9  ASUS ROG Zephyrus S17 (2020), 17.3\" FHD 300Hz/...     5 out of 5   \n",
       "\n",
       "              Product Price  \n",
       "0        Price: ₹ 78,993.00  \n",
       "1        Price: ₹ 84,990.00  \n",
       "2  Combo Price: ₹ 59,999.00  \n",
       "3        Price: ₹ 86,990.00  \n",
       "4        Price: ₹ 89,990.00  \n",
       "5        Price: ₹ 97,221.00  \n",
       "6        Price: ₹ 40,932.00  \n",
       "7      Price: ₹ 1,79,990.00  \n",
       "8        Price: ₹ 89,898.00  \n",
       "9      Price: ₹ 1,37,990.00  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all required libraires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\chromedriver.exe\")\n",
    "#To get the webpage\n",
    "url=\" https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#To search desired words in search box\n",
    "search_element=driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]')\n",
    "search_element.send_keys(\"laptops\")\n",
    "\n",
    "search_button=driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]')\n",
    "search_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#To select filter option.\n",
    "search_filter1=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label')\n",
    "search_filter1.click()\n",
    "search_filter2=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/div/label')\n",
    "search_filter2.click()\n",
    "time.sleep(2)\n",
    "#To fetch the product detaiils for each product.\n",
    "\n",
    "laptop_rating=[]\n",
    "product_name=[]\n",
    "price=[]\n",
    "product_ele=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "time.sleep(3)\n",
    "t=1\n",
    "for i in product_ele:\n",
    "    time.sleep(3)\n",
    "    i.click()   \n",
    "    time.sleep(2)\n",
    "    p=driver.current_window_handle\n",
    "    chwd=driver.window_handles\n",
    "    time.sleep(1)\n",
    "    driver.switch_to.window(chwd[1])\n",
    "    try:\n",
    "        review_rat=driver.find_element_by_xpath('//span[@class=\"a-size-base a-nowrap\"]')\n",
    "        time.sleep(2)    \n",
    "        laptop_rating.append(review_rat.text)\n",
    "        time.sleep(2)\n",
    "        product_title=driver.find_element_by_xpath('//span[@id=\"productTitle\"]')\n",
    "        product_name.append(product_title.text)\n",
    "        time.sleep(2)\n",
    "        price_element=driver.find_element_by_xpath('//tr[@id=\"priceblock_ourprice_row\"]')\n",
    "        price.append(price_element.text)\n",
    "    except:\n",
    "        pass\n",
    "    driver.close()\n",
    "    driver.switch_to.window(p)\n",
    "    \n",
    "#have used try and except function becuase some products ratings are missing.\n",
    "\n",
    "data={\"Product Title\":product_name,\n",
    "     \"Product Rating\":laptop_rating,\n",
    "      \"Product Price\":price}\n",
    "report=pd.DataFrame(dict([(k,pd.Series(v)) for k,v in data.items()]))\n",
    "report[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
